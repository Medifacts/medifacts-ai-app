"""
FastAPI backend for MediFacts.AI
================================

This module provides a minimal backend implementation for the MediFacts.AI
service described in the provided project summary.  The system allows
users to upload medical documents, pay a one‑time fee via Stripe and
receive a human‑readable explanation of the contents generated by
OpenAI’s GPT‑4o model.  It also supports follow‑up questions, PDF
report generation and optional email delivery.

Key features implemented in this proof of concept:

* **File upload** – accepts `.pdf`, `.txt`, `.jpg`, `.jpeg` and `.png`
  documents as specified in the requirements【318083594920458†L14-L18】.
* **Payment integration** – creates a Stripe Checkout session for a
  single analysis fee【318083594920458†L26-L28】.  URLs are returned
  to the caller for redirection on the client side.
* **AI analysis** – upon successful payment, the file content is
  extracted, a prompt is composed and GPT‑4o is called via the
  OpenAI API to produce a concise explanation in the user’s native
  language【318083594920458†L16-L20】.  A friendly “family doctor” tone
  is enforced through the system prompt【318083594920458†L30-L31】.
* **PDF generation** – the AI’s answer is rendered into a PDF using
  ReportLab and offered for download【318083594920458†L22-L23】.
* **Email delivery** – a stub `send_email` function demonstrates how
  to attach the generated PDF and send it via SMTP【318083594920458†L24-L25】.
* **Follow‑up questions** – users can ask up to three follow‑up
  questions related to the original document【318083594920458†L20-L21】.

This code is intentionally kept simple and easy to understand.  It does
not include a web frontend or any persistent storage; sessions live in
memory, so in a production deployment you would need to store session
data in a database and secure all credentials.  Replace the placeholder
API keys and SMTP settings with your own values before running.
"""

import os
import uuid
from tempfile import NamedTemporaryFile
from typing import Dict, List

# aiofiles is not available in this runtime environment; use built-in open instead
try:
    import aiofiles  # type: ignore
except ImportError:
    aiofiles = None
from fastapi import FastAPI, File, Form, HTTPException, UploadFile
from fastapi.responses import JSONResponse, StreamingResponse
from fastapi.responses import FileResponse
from fastapi.staticfiles import StaticFiles

try:
    import openai  # type: ignore
except ImportError:
    openai = None  # placeholder if the package isn’t installed
try:
    import stripe  # type: ignore
except ImportError:
    stripe = None  # placeholder if the package isn’t installed

try:
    from reportlab.lib.pagesizes import letter  # type: ignore
    from reportlab.pdfgen import canvas  # type: ignore
except ImportError:
    letter = None
    canvas = None

app = FastAPI()

# In‑memory store for conversations; keys are session IDs returned from
# the Stripe success callback.  Each entry stores the message history
# used by GPT‑4o and how many questions remain.
conversations: Dict[str, Dict[str, object]] = {}

# Flag to disable payment processing.  When true, the application
# bypasses Stripe Checkout and immediately performs the AI analysis
# upon file upload.  You can set the environment variable
# `SKIP_PAYMENT=true` to activate this behaviour, which is useful
# during development or when payments are not yet configured.
SKIP_PAYMENT = os.getenv("SKIP_PAYMENT", "true").lower() == "true"

# Configure API keys.  In production these should come from secure
# environment variables and not be hard‑coded.
openai_api_key = os.getenv("OPENAI_API_KEY", "your-openai-key")
stripe_secret_key = os.getenv("STRIPE_SECRET_KEY", "your-stripe-secret-key")

if openai is not None:
    openai.api_key = openai_api_key
if stripe is not None:
    stripe.api_key = stripe_secret_key


@app.post("/upload/")
async def upload_file(
    file: UploadFile = File(...),
    email: str | None = Form(None),
    currency: str = Form("eur"),
    amount: int = Form(1000),  # amount in cents
):
    """Handle file uploads and initiate a Stripe Checkout session.

    Parameters
    ----------
    file: UploadFile
        The medical document uploaded by the user.
    email: str | None
        Optional email address for sending the PDF report【318083594920458†L24-L25】.
    currency: str
        Currency for the Stripe payment (default: EUR).
    amount: int
        Payment amount in the smallest currency unit (default: 1000 for €10).

    Returns
    -------
    dict
        JSON containing the Stripe Checkout URL.
    """
    # Validate file type according to the project specification【318083594920458†L14-L18】.
    allowed_ext = {".pdf", ".txt", ".png", ".jpg", ".jpeg"}
    _, ext = os.path.splitext(file.filename or "")
    if ext.lower() not in allowed_ext:
        raise HTTPException(status_code=400, detail="Unsupported file type.")

    # Save the uploaded file to a temporary location.  If aiofiles is installed
    # use it for async I/O, otherwise fall back to synchronous writes.
    temp_filename = f"/tmp/{uuid.uuid4().hex}{ext.lower()}"
    content = await file.read()
    if aiofiles is not None:
        async with aiofiles.open(temp_filename, "wb") as out_file:
            await out_file.write(content)
    else:
        # Write synchronously when aiofiles is unavailable
        with open(temp_filename, "wb") as out_file:
            out_file.write(content)

    # If payment is disabled (development mode), perform analysis directly
    # without invoking Stripe.  Otherwise create a Checkout session.
    if SKIP_PAYMENT:
        # Generate a synthetic session ID for tracking
        session_id = uuid.uuid4().hex
        # Perform analysis and return the result
        try:
            text = await extract_text(temp_filename)
        except Exception as exc:
            raise HTTPException(status_code=500, detail=f"Text extraction failed: {exc}")
        system_prompt = (
            "You are a compassionate family doctor. Explain the medical document "
            "to the patient in plain language, using their native tongue. Provide "
            "a concise summary and avoid jargon."
        )
        user_prompt = f"Explain the following medical document:\n{text}"
        if openai is None:
            raise HTTPException(status_code=500, detail="OpenAI library not installed.")
        try:
            response = openai.ChatCompletion.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt},
                ],
                temperature=0.7,
                max_tokens=1024,
            )
            ai_answer = response.choices[0].message["content"]  # type: ignore[index]
        except Exception as exc:
            raise HTTPException(status_code=500, detail=f"OpenAI call failed: {exc}")
        # Generate PDF
        pdf_basename = f"{uuid.uuid4().hex}.pdf"
        pdf_path = f"/tmp/{pdf_basename}"
        generate_pdf(ai_answer, pdf_path)
        # Optionally send email
        if email:
            try:
                send_email(email, ai_answer, pdf_path)
            except Exception as exc:
                print(f"Email send failed: {exc}")
        # Store conversation
        conversations[session_id] = {
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt},
                {"role": "assistant", "content": ai_answer},
            ],
            "remaining_questions": 3,
        }
        return {
            "answer": ai_answer,
            "pdf_download": f"/download/{pdf_basename}",
            "session_id": session_id,
        }
    else:
        # Payment flow: create a Stripe Checkout session for the one‑time analysis fee【318083594920458†L26-L28】.
        if stripe is None:
            raise HTTPException(status_code=500, detail="Stripe library not installed.")
        try:
            checkout_session = stripe.checkout.Session.create(
                payment_method_types=["card"],
                line_items=[
                    {
                        "price_data": {
                            "currency": currency,
                            "product_data": {"name": "MediFacts Analysis"},
                            "unit_amount": amount,
                        },
                        "quantity": 1,
                    }
                ],
                mode="payment",
                success_url=(
                    f"http://localhost:8000/success/{{CHECKOUT_SESSION_ID}}"
                    f"?file_path={temp_filename}&email={email or ''}"
                ),
                cancel_url="http://localhost:8000/cancel",
            )
        except Exception as e:
            return JSONResponse(status_code=500, content={"error": str(e)})
        return {"checkout_url": checkout_session.url}


@app.get("/success/{session_id}")
async def payment_success(session_id: str, file_path: str, email: str | None = None):
    """Stripe success callback.

    Once payment completes, this endpoint extracts the file’s text,
    invokes GPT‑4o to generate an explanation, builds a PDF report and
    stores the conversation for follow‑up questions.  It returns the
    answer and a link to download the generated PDF【318083594920458†L22-L23】.
    """
    # Extract text from the uploaded document.
    try:
        text = await extract_text(file_path)
    except Exception as exc:
        return JSONResponse(status_code=500, content={"error": f"Failed to extract text: {exc}"})

    # Compose the prompt for GPT‑4o.  The system prompt sets a warm,
    # human tone reminiscent of a family doctor【318083594920458†L30-L31】.
    system_prompt = (
        "You are a compassionate family doctor. Explain the medical document "
        "to the patient in plain language, using their native tongue. Provide "
        "a concise summary and avoid jargon."
    )
    user_prompt = f"Explain the following medical document:\n{text}"

    # Call the OpenAI API.  The library may not be installed in the
    # environment, so we check and handle gracefully.
    if openai is None:
        return JSONResponse(status_code=500, content={"error": "OpenAI library not installed."})
    try:
        response = openai.ChatCompletion.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt},
            ],
            temperature=0.7,
            max_tokens=1024,
        )
        ai_answer = response.choices[0].message["content"]  # type: ignore[index]
    except Exception as exc:
        return JSONResponse(status_code=500, content={"error": f"OpenAI call failed: {exc}"})

    # Generate the PDF report.
    pdf_basename = f"{uuid.uuid4().hex}.pdf"
    pdf_path = f"/tmp/{pdf_basename}"
    try:
        generate_pdf(ai_answer, pdf_path)
    except Exception as exc:
        return JSONResponse(status_code=500, content={"error": f"Failed to generate PDF: {exc}"})

    # Optionally send the report via email.
    if email:
        try:
            send_email(email, ai_answer, pdf_path)
        except Exception as exc:
            # Log but do not fail the request on email issues.
            print(f"Email sending failed: {exc}")

    # Store conversation state for follow‑up questions【318083594920458†L20-L21】.
    conversations[session_id] = {
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt},
            {"role": "assistant", "content": ai_answer},
        ],
        "remaining_questions": 3,
    }

    return {
        "answer": ai_answer,
        "pdf_download": f"/download/{pdf_basename}",
        "session_id": session_id,
    }


@app.get("/download/{pdf_name}")
async def download_pdf(pdf_name: str):
    """Serve a generated PDF to the caller.
    Clients can open the returned URL to retrieve the PDF report.
    """
    pdf_path = f"/tmp/{pdf_name}"
    if not os.path.exists(pdf_path):
        raise HTTPException(status_code=404, detail="PDF not found.")
    return StreamingResponse(open(pdf_path, "rb"), media_type="application/pdf")


@app.post("/ask/{session_id}")
async def ask_follow_up(session_id: str, question: str = Form(...)):
    """Handle a follow‑up question.

    Users may ask up to three additional questions related to the
    original document【318083594920458†L20-L21】.  The conversation
    history is preserved to maintain context【318083594920458†L59-L60】.
    """
    session = conversations.get(session_id)
    if not session:
        raise HTTPException(status_code=404, detail="Session not found.")
    if session["remaining_questions"] <= 0:
        raise HTTPException(status_code=400, detail="No more follow‑up questions available.")

    # Append the new question to the message history.
    session_messages: List[Dict[str, str]] = session["messages"]  # type: ignore[assignment]
    session_messages.append({"role": "user", "content": question})

    # Call GPT‑4o with the full history.  This leverages GPT’s ability to
    # remember context without a dedicated question module【318083594920458†L59-L60】.
    if openai is None:
        raise HTTPException(status_code=500, detail="OpenAI library not installed.")
    try:
        response = openai.ChatCompletion.create(
            model="gpt-4o",
            messages=session_messages,
            temperature=0.7,
            max_tokens=512,
        )
        follow_up = response.choices[0].message["content"]  # type: ignore[index]
    except Exception as exc:
        raise HTTPException(status_code=500, detail=f"OpenAI call failed: {exc}")

    # Append the assistant’s response to the history and decrement the counter.
    session_messages.append({"role": "assistant", "content": follow_up})
    session["remaining_questions"] -= 1

    return {
        "answer": follow_up,
        "remaining_questions": session["remaining_questions"],
    }


async def extract_text(file_path: str) -> str:
    """Extract plain text from supported document types.

    This helper handles PDFs, text files and common image formats.  For
    images it uses Tesseract OCR via pytesseract.  If the necessary
    libraries are missing, an exception is raised.  In production you
    should handle more error cases (e.g. corrupt files).
    """
    lower_path = file_path.lower()
    # Text files can be read directly
    if lower_path.endswith(".txt"):
        async with aiofiles.open(file_path, "r") as f:
            return await f.read()
    # PDF extraction using PyPDF2
    elif lower_path.endswith(".pdf"):
        try:
            import PyPDF2  # type: ignore
        except ImportError:
            raise RuntimeError("PyPDF2 is not installed.")
        text = ""
        with open(file_path, "rb") as f:
            reader = PyPDF2.PdfReader(f)
            for page in reader.pages:
                # Some PDFs may not contain extractable text; fallback to empty string.
                text += page.extract_text() or ""
        return text
    # Image extraction via pytesseract
    elif lower_path.endswith(('.png', '.jpg', '.jpeg')):
        try:
            import pytesseract  # type: ignore
            from PIL import Image  # type: ignore
        except ImportError:
            raise RuntimeError("pytesseract and pillow are required for image OCR.")
        image = Image.open(file_path)
        return pytesseract.image_to_string(image)
    else:
        raise ValueError("Unsupported file type for extraction.")


def generate_pdf(text: str, output_path: str) -> None:
    """Render a plain text string into a simple PDF file.

    Uses the ReportLab library to draw lines of text onto the page.  If
    ReportLab is not installed the function raises an exception.  Long
    lines are not wrapped; you may need to implement your own
    wrapping logic or use a higher‑level PDF generation library such as
    `pdfkit` as suggested in the requirements【318083594920458†L43-L44】.
    """
    if canvas is None or letter is None:
        raise RuntimeError("ReportLab is not installed.")
    c = canvas.Canvas(output_path, pagesize=letter)
    width, height = letter
    margin = 72  # 1‑inch margin
    y = height - margin
    line_height = 14
    for line in text.splitlines():
        # If we reach the bottom of the page, start a new one
        if y < margin:
            c.showPage()
            y = height - margin
        c.drawString(margin, y, line)
        y -= line_height
    c.save()


def send_email(to_email: str, body: str, attachment_path: str) -> None:
    """Send an email with the report attached.

    This is a stub implementation that builds an email message with an
    attached PDF but does not actually connect to an SMTP server.  In
    production you would configure `smtplib` or use a service like
    SendGrid as outlined in the project summary【318083594920458†L44-L45】.
    """
    # The email module is part of the Python standard library
    import smtplib
    from email.message import EmailMessage
    from email.utils import make_msgid

    msg = EmailMessage()
    msg["Subject"] = "MediFacts AI Report"
    msg["From"] = "no-reply@medifacts.ai"
    msg["To"] = to_email
    msg.set_content(body)

    # Attach the PDF
    with open(attachment_path, "rb") as f:
        pdf_data = f.read()
    msg.add_attachment(
        pdf_data,
        maintype="application",
        subtype="pdf",
        filename="report.pdf",
    )

    # Example SMTP usage (commented out)
    # with smtplib.SMTP_SSL("smtp.example.com", 465) as server:
    #     server.login("username", "password")
    #     server.send_message(msg)

    # For this demonstration we simply print a message to the console
    print(f"Prepared email to {to_email} (SMTP sending not configured).")

# ---------------------------------------------------------------------------
# Static file serving and root endpoint
#
# Mount the `web` directory so that the HTML/JS frontend can be accessed
# directly via the FastAPI server.  When the server is run with
# `uvicorn app:app`, navigating to `/` will return the index.html file.
app.mount("/static", StaticFiles(directory=os.path.join(os.path.dirname(__file__), "web")), name="static")


@app.get("/")
async def read_index() -> FileResponse:
    """Serve the single‑page application.

    Returns the `index.html` file located in the `web` subdirectory of
    this module.  Clients can open `http://localhost:8000/` to load the
    uploader interface and follow‑up question form.
    """
    index_path = os.path.join(os.path.dirname(__file__), "web", "index.html")
    return FileResponse(index_path)